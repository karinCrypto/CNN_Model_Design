{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "6KnwCFsNK_2i",
        "PrKxN3M-LGRw",
        "q_3f9qtXLKJQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonai/HK_LSTMSenfuClass/blob/main/Day1/CNN/%5B1%5DVGG_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGGNet for Color Images (RGB, CIFAR-10)\n",
        "## TensorFlow/Keras version"
      ],
      "metadata": {
        "id": "VG5Bu-Kd9-jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRcMh-6uKTSd"
      },
      "outputs": [],
      "source": [
        "import os, random, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Reproducibility & Device"
      ],
      "metadata": {
        "id": "caX_syK3LM0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "fix_seed(42)\n"
      ],
      "metadata": {
        "id": "ACxI_AumLBko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # set memory growth instead of pre-allocating all VRAM\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"✅ GPU detected: {tf.config.experimental.get_device_details(gpus[0]).get('device_name','GPU')}\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not set memory growth:\", e)\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqimbYkJukIE",
        "outputId": "d39c4cf0-0a53-47aa-8e01-3e54cc99adf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU detected: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Hyper-params & constants\n",
        " #####   ( use_bn_dropout: bool = True 로 변경하면 bn_dropout 예제, use_augmentation: bool = True 로 변경하면 augmentation 예제 )"
      ],
      "metadata": {
        "id": "A3FJF87wLUhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class CFG:\n",
        "    img_size: int = 32\n",
        "    num_classes: int = 10\n",
        "    width: int = 16           # base width (like PyTorch code)\n",
        "    p_dropout: float = 0.25   # for BN/Dropout variant\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 50\n",
        "    lr: float = 1e-2\n",
        "    use_bn_dropout: bool = True   # toggle VGG16withBN+Dropout variant\n",
        "    use_augmentation: bool = False\n",
        "    out_dir: str = \"ckpt_tf/vgg16_rgb_bn\"  # folder will be renamed based on flag"
      ],
      "metadata": {
        "id": "wmEXfyG3LT_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = CFG()\n",
        "CFG.out_dir = f\"ckpt_tf/{'vgg16_rgb_bn' if CFG.use_bn_dropout else 'vgg16_rgb'}\"\n",
        "os.makedirs(CFG.out_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "TeDhH8Rju2-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 mean/std in RGB order (same as PyTorch version)\n",
        "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
        "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)"
      ],
      "metadata": {
        "id": "y9084hEbu4Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Data: CIFAR-10 (RGB)"
      ],
      "metadata": {
        "id": "0nf4iilivAHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar10_datasets(use_augmentation=True):\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    y_train = y_train.squeeze()\n",
        "    y_test = y_test.squeeze()\n",
        "    x_train = x_train.astype(np.float32) / 255.0\n",
        "    x_test  = x_test.astype(np.float32) / 255.0\n",
        "\n",
        "    def normalize(img):\n",
        "        return (img - CIFAR10_MEAN) / CIFAR10_STD\n",
        "\n",
        "    def augment(img, lbl):\n",
        "        # --- 추가 옵션 ---\n",
        "        if use_augmentation:\n",
        "            img = tf.image.resize_with_crop_or_pad(img, CFG.img_size + 4, CFG.img_size + 4)\n",
        "            img = tf.image.random_crop(img, size=[CFG.img_size, CFG.img_size, 3])\n",
        "            img = tf.image.random_flip_left_right(img)\n",
        "            img = tf.image.random_brightness(img, max_delta=0.1)\n",
        "            img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
        "            img = tf.image.random_saturation(img, lower=0.8, upper=1.2)\n",
        "        img = normalize(img)\n",
        "        return img, lbl\n",
        "\n",
        "    def preprocess(img, lbl):\n",
        "        img = tf.image.resize(img, (CFG.img_size, CFG.img_size))\n",
        "        img = normalize(img)\n",
        "        return img, lbl\n",
        "\n",
        "    train_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "        .shuffle(10000, seed=42)\n",
        "        .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(CFG.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    test_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "        .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(CFG.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    return train_ds, test_ds"
      ],
      "metadata": {
        "id": "7p13eLV3vEs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds = get_cifar10_datasets(use_augmentation=CFG.use_augmentation)"
      ],
      "metadata": {
        "id": "XBo3OETavI-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) VGG-style building blocks"
      ],
      "metadata": {
        "id": "rn4ZfibD-IOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def ConvBlock(x, out_ch, num_layers=2, use_bn=False):\n",
        "    for _ in range(num_layers):\n",
        "        x = layers.Conv2D(out_ch, kernel_size=3, strides=1, padding=\"same\",\n",
        "                          use_bias=not use_bn,\n",
        "                          kernel_initializer=\"he_normal\")(x)\n",
        "        if use_bn:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "soRdZPbmvN9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LinearBlock(x, out_dim, p_drop=0.0, use_dropout=False):\n",
        "    # PyTorch code uses 3 linear layers ending with num_classes\n",
        "    # We already have GAP -> (width*4) features; mirror that:\n",
        "    x = layers.Dense(x.shape[-1], kernel_initializer=\"he_normal\")(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(p_drop)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Dense(x.shape[-1], kernel_initializer=\"he_normal\")(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(p_drop)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Dense(out_dim)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Yx3rsdmivSNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg16(img_channels=3, width=16, num_classes=10, use_bn_dropout=False, p=0.25):\n",
        "    inp = layers.Input(shape=(CFG.img_size, CFG.img_size, img_channels))\n",
        "\n",
        "    # Five conv blocks with 2,2,3,3,3 conv layers (as in the PyTorch version)\n",
        "    x = ConvBlock(inp, width,     num_layers=2, use_bn=use_bn_dropout)\n",
        "    x = layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    x = ConvBlock(x,   width*2,   num_layers=2, use_bn=use_bn_dropout)\n",
        "    x = layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    x = ConvBlock(x,   width*4,   num_layers=3, use_bn=use_bn_dropout)\n",
        "    x = layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    x = ConvBlock(x,   width*4,   num_layers=3, use_bn=use_bn_dropout)\n",
        "    x = layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    x = ConvBlock(x,   width*4,   num_layers=3, use_bn=use_bn_dropout)\n",
        "    x = layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    # GAP to mimic AdaptiveAvgPool2d(1).flatten\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Classifier (with optional Dropout, as in VGG16withBN)\n",
        "    x = LinearBlock(x, num_classes, p_drop=p, use_dropout=use_bn_dropout)\n",
        "\n",
        "    return models.Model(inp, x, name=\"VGG16_TF\" + (\"_BN\" if use_bn_dropout else \"\"))"
      ],
      "metadata": {
        "id": "CNFtIUg7vT_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_vgg16(img_channels=3,\n",
        "                    width=CFG.width,\n",
        "                    num_classes=CFG.num_classes,\n",
        "                    use_bn_dropout=CFG.use_bn_dropout,\n",
        "                    p=CFG.p_dropout)"
      ],
      "metadata": {
        "id": "wn-lJwOkvZMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Compile & Callbacks"
      ],
      "metadata": {
        "id": "nAb3RQDD_zeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SGD(m=0.9) to match the PyTorch script\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=CFG.lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "rm4oFoqWvlDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "\n",
        "ckpt_best = os.path.join(CFG.out_dir, \"best.weights.h5\")\n",
        "ckpt_last = os.path.join(CFG.out_dir, \"latest.weights.h5\")"
      ],
      "metadata": {
        "id": "jfbaBsb-vtsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbs = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(ckpt_best, monitor=\"val_acc\",\n",
        "                                       save_best_only=True, save_weights_only=True, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(ckpt_last, monitor=\"val_acc\",\n",
        "                                       save_best_only=False, save_weights_only=True, verbose=0),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "3nsWESGvvvoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "y-2wGOlpvxJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Train"
      ],
      "metadata": {
        "id": "nAa4zBPwAY-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=CFG.epochs,\n",
        "    callbacks=cbs\n",
        ")"
      ],
      "metadata": {
        "id": "1XCHMR1av31U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist.history[\"loss\"], label=\"train\")\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"val\")\n",
        "plt.title(\"Loss (Training vs. Validation)\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.out_dir, \"loss.png\")); plt.close()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist.history[\"acc\"], label=\"train\")\n",
        "plt.plot(hist.history[\"val_acc\"], label=\"val\")\n",
        "plt.title(\"Accuracy (Training vs. Validation)\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.out_dir, \"accuracy.png\")); plt.close()"
      ],
      "metadata": {
        "id": "q7xYNLEhv651"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Inference helper (evaluate)"
      ],
      "metadata": {
        "id": "sJLPAkJMwELq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(weights_path: str, batch_size: int = 64):\n",
        "    \"\"\"Load weights and evaluate on CIFAR-10 test set.\"\"\"\n",
        "    tmp_model = build_vgg16(img_channels=3, width=CFG.width,\n",
        "                            num_classes=CFG.num_classes,\n",
        "                            use_bn_dropout=CFG.use_bn_dropout, p=CFG.p_dropout)\n",
        "    tmp_model.compile(optimizer=\"sgd\",\n",
        "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                      metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "    tmp_model.load_weights(weights_path)\n",
        "    print(f\"Loaded weights from: {weights_path}\")\n",
        "    results = tmp_model.evaluate(test_ds, verbose=1)\n",
        "    print(f\"[Test] Loss: {results[0]:.4f} | Acc.: {results[1]:.4f}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "ZAbjfFOyCjjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def save_trained_model(save_path):\n",
        "  model.save_weights(save_path)\n",
        "  print(f\"✅ 모델 가중치 저장 완료: {save_path}\")\n",
        "\n",
        "  files.download(save_path)"
      ],
      "metadata": {
        "id": "Vo-MASdt1PCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### # Example:\n",
        "inference(ckpt_last)\n",
        "\n",
        "inference(ckpt_best)\n",
        "###"
      ],
      "metadata": {
        "id": "OVre1umVItTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # quick test: evaluate last checkpoint\n",
        "    try:\n",
        "        inference(ckpt_last)\n",
        "        save_path = \"/content/ckpt_tf/vgg16_rgb_final.weights.h5\"\n",
        "        save_trained_model(save_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Inference skipped (weights might not be saved yet):\", e)"
      ],
      "metadata": {
        "id": "hdju3ottwf9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
