{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained CNN Inference Example (TensorFlow version)\n",
        "### Dataset: cats_and_dogs_filtered\n",
        "### Models: VGG16, ResNet50, MobileNetV2 (TensorFlow Hub / Keras Applications)"
      ],
      "metadata": {
        "id": "VG5Bu-Kd9-jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MRcMh-6uKTSd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Dataset (cats & dogs)"
      ],
      "metadata": {
        "id": "caX_syK3LM0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "!unzip -qq cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "XT09BCS672nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptq5wFt57tsk",
        "outputId": "0789f1f2-9a53-466f-f83e-87afcbda44d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats_and_dogs_filtered\tcats_and_dogs_filtered.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = os.path.join(\"/content/\", \"cats_and_dogs_filtered\")\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir   = os.path.join(base_dir, \"validation\")"
      ],
      "metadata": {
        "id": "0Zedo2XH8Y7k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg55dZCh8HCM",
        "outputId": "01701cd1-2429-4d8e-8b12-cafe4474d766"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cats_and_dogs_filtered/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/cats_and_dogs_filtered/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIE6tww48QmL",
        "outputId": "0ee6ebe3-7efa-4a9b-e76e-7536f19ce968"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats  dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE   = (224, 224)\n",
        "BATCH_SIZE = 1  # inference 용도로 1 권장\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    val_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qpjE_R3_WBL",
        "outputId": "cdc68a96-aa28-42ea-b7e5-0c78ea6ebebd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = val_ds.class_names\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "val_ds = val_ds.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "CQrCEG0z_d-Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Models & preprocess map"
      ],
      "metadata": {
        "id": "TUsozq0GasaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_pre\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_pre\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "def get_model_and_preprocess(model_name: str):\n",
        "    \"\"\"Return (keras_model, preprocess_fn) by name.\"\"\"\n",
        "    print(model_name)\n",
        "    name = model_name.strip().lower()\n",
        "    print(name)\n",
        "    if name == \"vgg16\":\n",
        "        return VGG16(weights=\"imagenet\"), vgg_pre\n",
        "    if name == \"resnet50\":\n",
        "        return ResNet50(weights=\"imagenet\"), resnet_pre\n",
        "    if name == \"mobilenetv2\":\n",
        "        return MobileNetV2(weights=\"imagenet\"), mobilenet_pre\n",
        "    raise ValueError(f\"Unsupported model name: {model_name}\")"
      ],
      "metadata": {
        "id": "ACxI_AumLBko"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Pretty summary printer"
      ],
      "metadata": {
        "id": "A3FJF87wLUhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_summary(model_name):\n",
        "    model, _ = get_model_and_preprocess(model_name)\n",
        "    print(f\"\\n===== Summary: {model.name} =====\")\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "t5Y_EXoPBYII"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Inference (by model name)"
      ],
      "metadata": {
        "id": "dBe0z3JGa-bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(model_name, num_sample_show):\n",
        "    model, pre_fn = get_model_and_preprocess(model_name)\n",
        "    print(f\"\\n\\n================ Inference: {model.name} ================\")\n",
        "    cnt = 0\n",
        "    for images, labels in val_ds:\n",
        "        # batch_size=1이므로 [0]만 사용\n",
        "        img_uint8 = images[0].numpy().astype(\"uint8\")\n",
        "        gt_idx = int(labels[0].numpy())\n",
        "\n",
        "        # preprocess & predict\n",
        "        x = tf.cast(images, tf.float32)  # [1, H, W, 3]\n",
        "        x = pre_fn(x)\n",
        "        preds = model.predict(x, verbose=0)  # (1, 1000)\n",
        "        decoded = decode_predictions(preds, top=3)[0]\n",
        "\n",
        "        # show image\n",
        "        plt.figure(figsize=(4,4))\n",
        "        plt.imshow(img_uint8)\n",
        "        plt.title(f\"GT: {class_names[gt_idx]}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Top-3 Predictions:\")\n",
        "        for (_, name, score) in decoded:\n",
        "            print(f\" - {name:15s}: {score*100:.2f}%\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        cnt += 1\n",
        "        if cnt >= num_sample_show:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "NPt-5hCrbA26"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 모델별 추론 테스트"
      ],
      "metadata": {
        "id": "YxdPZ2bGbDU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16 with Batch-Norm."
      ],
      "metadata": {
        "id": "Z-5D0s3S7xLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_summary(\"VGG16\")\n",
        "run_inference(\"VGG16\", 5)"
      ],
      "metadata": {
        "id": "-9FZLae47SnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50"
      ],
      "metadata": {
        "id": "_oWu8qsL70HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_summary(\"ResNet50\")\n",
        "run_inference(\"ResNet50\", 5)"
      ],
      "metadata": {
        "id": "O_KocpmV7TCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV2"
      ],
      "metadata": {
        "id": "tcCmLjQ_7uFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_summary(\"MobileNetV2\")\n",
        "run_inference(\"MobileNetV2\", 5)"
      ],
      "metadata": {
        "id": "J54eTFHT3bX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}